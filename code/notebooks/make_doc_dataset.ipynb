{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39dc1467-37c1-4471-b84e-b8b4d745365e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from transformers import RobertaTokenizer, T5ForConditionalGeneration, T5Config, T5Model\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from helper import get_j_c_data_loaders, to_device, get_device, plot_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91ad7f16-8694-4516-a4d8-4836b384ed42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBALS\n",
    "device = get_device()\n",
    "BEAM_SIZE = 10\n",
    "MAX_SEQ_LEN = 200\n",
    "SOURCE_LEN = 200\n",
    "LEARNING_RATE = 5e-4\n",
    "EPOCHS = 7\n",
    "BATCH_SIZE = 128 # change depending on the GPU Colab gives you\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c29f2ed5-05ef-48f1-be73-8855c7622eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import RobertaTokenizer, T5ForConditionalGeneration\n",
    "\n",
    "model_name_or_path = 'models/java2doc' \n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('Salesforce/codet5-base')\n",
    "model = to_device(T5ForConditionalGeneration.from_pretrained(model_name_or_path), device)\n",
    "\n",
    "train_dl , valid_dl, test_dl = get_j_c_data_loaders(BATCH_SIZE, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da701694-8fbc-402a-9599-7051a41a617c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(clf, dl):\n",
    "    sent_data = []\n",
    "    for data in tqdm(dl):\n",
    "        with torch.no_grad():\n",
    "            gen = model.generate(data['j_ids'], max_length=MAX_SEQ_LEN, attention_mask=data['j_mask'], num_beams=5)\n",
    "            sent_data += [tokenizer.decode(entry, skip_special_tokens=True) for entry in gen]\n",
    "    \n",
    "    return sent_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26e33cbb-045e-447e-b896-f1beff4f3a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81/81 [07:19<00:00,  5.43s/it]\n",
      "100%|██████████| 4/4 [00:22<00:00,  5.65s/it]\n",
      "100%|██████████| 8/8 [01:00<00:00,  7.54s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "doc_data = [sample(model, dl) for dl in (train_dl, valid_dl, test_dl)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65f8f1a7-9d52-49d0-b68e-70ef3d1ea4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"../../datasets/\"\n",
    "\n",
    "for name, d_data in zip(('train.doc.txt', 'valid.doc.txt' , 'test.doc.txt'), tuple(doc_data)):\n",
    "    with open(dataset_path + name, 'w') as f:\n",
    "        for item in d_data:\n",
    "            f.write(\"%s\\n\" % item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
